{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "housing = loadmat('./homework3/data/housing.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Info about the dataset\n",
    "# https://archive.ics.uci.edu/ml/datasets/Housing\n",
    "# Gelman on Standardization: \n",
    "# http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf\n",
    "# Stats Overflow on standardization:\n",
    "# http://stats.stackexchange.com/questions/7112/when-and-how-to-use-standardized-explanatory-variables-in-linear-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = housing['data']\n",
    "y_train = housing['labels']\n",
    "\n",
    "X_test = housing['testdata']\n",
    "y_test = housing['testlabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22.57470356])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# (a) Compute the ordinary least squares (OLS) estimator based on the training data. (You can\n",
    "# use whatever software you like to do this.) Here, you should consider the model that also\n",
    "# incorporates the intercept parameter. What is the numerical value of the intercept term?\n",
    "# How is it related to the training labels? Justify your answer.\n",
    "\n",
    "ols_clf = linear_model.LinearRegression()\n",
    "ols_clf.fit(X_train, y_train)\n",
    "ols_clf.intercept_\n",
    "\n",
    "# Explanation:\n",
    "# The intercept is: 22.57470356.  This number is equal to the the mean (22.57470355) of the training outcomes, \n",
    "# which makes sense given that the data has been standardized.  In effect, the standardization process has \n",
    "# shifted the data so the mean of the output is centered around 0.  Without considering any other factors, \n",
    "# you'd expect the value of the house to be the expected value of the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MSE: 22.1037987797\n",
      "Testing MSE 24.4065641284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (b) What is the average squared loss of the OLS estimator (from part (a)) on the training data?\n",
    "# And on the test data?\n",
    "train_mse = np.mean((ols_clf.predict(X_train) - y_train) ** 2)\n",
    "test_mse = np.mean((ols_clf.predict(X_test) - y_test) ** 2)\n",
    "\n",
    "print \"\"\"Training MSE: {}\\nTesting MSE {}\n",
    "\"\"\".format(train_mse, test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use some existing software package to compute a sparse weight vector with at most three nonzero\n",
    "# entries (not including the “intercept”). This should be done just using the training data.\n",
    "# Report what software (e.g., the specific MATLAB/Python function) you used, and the names\n",
    "# of the variables (as given in https://archive.ics.uci.edu/ml/machine-learning-databases/\n",
    "# housing/housing.names) that have non-zero weight. Do these make sense to you?\n",
    "# Some suggested methods to use: Lasso, LARS (which is actually an algorithm for solving the\n",
    "# Lasso optimization problem with some additional convenient properties), stepwise regression,\n",
    "# orthogonal matching pursuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_squared_error(y_true, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_figs(fig_num, elev, azim, X_train, clf):\n",
    "    fig = plt.figure(fig_num, figsize=(4, 3))\n",
    "    plt.clf()\n",
    "    ax = Axes3D(fig, elev=elev, azim=azim)\n",
    "\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], y_train, c='k', marker='+')\n",
    "    ax.plot_surface(np.array([[-.1, -.1], [.15, .15]]),\n",
    "                    np.array([[-.1, .15], [-.1, .15]]),\n",
    "                    clf.predict(np.array([[-.1, -.1, .15, .15],\n",
    "                                          [-.1, .15, -.1, .15]]).T\n",
    "                                ).reshape((2, 2)),\n",
    "                    alpha=.5)\n",
    "    ax.set_xlabel('X_1')\n",
    "    ax.set_ylabel('X_2')\n",
    "    ax.set_zlabel('Y')\n",
    "    ax.w_xaxis.set_ticklabels([])\n",
    "    ax.w_yaxis.set_ticklabels([])\n",
    "    ax.w_zaxis.set_ticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.        , -0.04845853,  1.3690263 ,  0.2169913 ,  1.36541769,\n",
       "        -2.28090769,  1.76748029,  0.41869877, -3.39998654,  2.24417058,\n",
       "        -2.01260307, -1.83849873,  0.66867329, -4.60866407])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ols_clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Attribute Information\n",
    "# 0. Column of 1s to facilitate intercepts\n",
    "# 1. CRIM: per capita crime rate by town \n",
    "# 2. ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    "# 3. INDUS: proportion of non-retail business acres per town \n",
    "# 4. CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) \n",
    "# 5. NOX: nitric oxides concentration (parts per 10 million) \n",
    "# 6. RM: average number of rooms per dwelling \n",
    "# 7. AGE: proportion of owner-occupied units built prior to 1940 \n",
    "# 8. DIS: weighted distances to five Boston employment centres \n",
    "# 9. RAD: index of accessibility to radial highways \n",
    "# 10. TAX: full-value property-tax rate per $10,000\n",
    "# 11. PTRATIO: pupil-teacher ratio by town \n",
    "# 12. B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town \n",
    "# 13. LSTAT: % lower status of the population \n",
    "# 14. MEDV: Median value of owner-occupied homes in $1000's\n",
    "\n",
    "cols = ['INT', 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "df_train = pd.DataFrame(X_train, columns=cols)\n",
    "ser_train = pd.Series([y[0] for y in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.574703557312262"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
