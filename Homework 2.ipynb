{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "spam = loadmat('./homework2/data/spam_fixed.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_data = spam['data']\n",
    "spam_labels = spam['labels']\n",
    "spam_test_data = spam['testdata']\n",
    "spam_test_labels = spam['testlabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_errors(predictions, labels):\n",
    "    \"\"\" Generates a list of indexes of misclassified \n",
    "    examples\n",
    "    \"\"\"\n",
    "    zipped = zip(predictions, labels)\n",
    "    errors = [ix for ix, tup in enumerate(zipped)\n",
    "              if tup[0] != tup[1]]\n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_scikits_model(clf, test_data, test_labels):\n",
    "    preds = clf.predict(test_data)\n",
    "    errors = compute_errors(preds, [t[0] for t in test_labels])\n",
    "\n",
    "    return len(errors) / test_labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Averaged-Perceptron with 64 passes through the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(features,  weights):\n",
    "    \"\"\" \n",
    "    Predicts a label (1, -1) given a vector \n",
    "    of features and weights\n",
    "    \n",
    "    Args:\n",
    "        features:\n",
    "        weights:\n",
    "\n",
    "    Return:\n",
    "        prediction: int of -1 or 1\n",
    "    \"\"\"\n",
    "    prediction = np.dot(features, weights)\n",
    "    if prediction > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(prediction, label, features, weights):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        prediction: int of predicted label (1 or -1)\n",
    "        label: the true label of the data point (1 or -1)\n",
    "        features: numpy array of feature values\n",
    "        weights: 1d numpy array of weights for the features\n",
    "    \n",
    "    Returns:\n",
    "        weights: \n",
    "    \"\"\"\n",
    "    if prediction != label:\n",
    "        weights = weights + (label * features)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perceptron_fit(examples):\n",
    "    \"\"\" \n",
    "    Generates a vector of weights\n",
    "    \n",
    "    Args:\n",
    "        examples: vector of feature, label tuples\n",
    "    \n",
    "    Returns:\n",
    "        weights: d-dimensional vector of weights\n",
    "    \"\"\"\n",
    "    weights = np.zeros(examples[0][0].shape)\n",
    "    for features, label in examples:\n",
    "        prediction = predict(features, weights)\n",
    "        weights = update_weights(prediction, label[0], \n",
    "                                 features, weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add trained bias to signature and prediction\n",
    "def test_perceptron_model(predict, testdata, testlabels, trained_weights):\n",
    "    \"\"\" Generates predictions from a trained weight vector \"\"\"\n",
    "    preds = [predict(features, trained_weights)\n",
    "             for features in testdata]\n",
    "    errors = compute_errors(preds, [t[0] for t in testlabels])\n",
    "    \n",
    "    return len(errors) / testlabels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_perceptron_train(num_iterations, examples):\n",
    "    weights = np.zeros(examples[0][0].shape)\n",
    "    cweights = np.zeros(examples[0][0].shape)\n",
    "    bias = 0\n",
    "    cbias = 0\n",
    "    counter = 1\n",
    "    \n",
    "    for iteration in range(0, num_iterations):\n",
    "        np.random.shuffle(examples)\n",
    "        for features, label in examples:\n",
    "            if np.dot(features, weights) + bias <= 0:\n",
    "                # update the weights for this iteration\n",
    "                weights = weights + (label * features)\n",
    "                bias = bias + label\n",
    "                # update the cached weights\n",
    "                cweights = cweights + (label * counter * features)\n",
    "                cbias = bias + (label * counter)\n",
    "            counter += 1\n",
    "            \n",
    "    return (weights - ((1/counter) * cweights), bias - ((1/counter) * cbias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_perceptron_train(num_iterations, examples):\n",
    "    weights = np.zeros(examples[0][0].shape)\n",
    "    cweights = np.zeros(examples[0][0].shape)\n",
    "    bias = 0\n",
    "    counter = 1\n",
    "    \n",
    "    for iteration in range(0, num_iterations):\n",
    "        np.random.shuffle(examples)\n",
    "        for features, label in examples:\n",
    "            if np.dot(features, weights) <= 0:\n",
    "                # update the weights for this iteration\n",
    "                weights = weights + (label * features)\n",
    "                # update the cached weights\n",
    "                cweights = cweights + (label * counter * features)\n",
    "            counter += 1\n",
    "            \n",
    "    return weights - ((1/counter) * cweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_perceptron_test(features, weights, bias):\n",
    "    activation = np.dot(features, weights) + bias\n",
    "    if activation > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_perceptron_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-7d277e160466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mspam_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspam_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# trained_weights = fit(spam_examples)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrained_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_perceptron_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspam_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspam_test_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspam_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'avg_perceptron_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Averaged-Perceptron with 64 passes through the data.\n",
    "spam_examples = zip(spam_data, spam_labels)\n",
    "# trained_weights = fit(spam_examples)\n",
    "trained_weights = avg_perceptron_train(64, spam_examples)\n",
    "test_model(spam_test_data, spam_test_labels, trained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Logistic regression model with MLE for parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07747395833333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(spam_data, np.ravel(spam_labels))\n",
    "test_scikits_model(clf, spam_test_data, spam_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3  Generative model classifier where class conditional distributions are multivariate Gaussian distributions with shared covariance matrix for all classes. Use MLE for parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12239583333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(spam_data, np.ravel(spam_labels))\n",
    "test_scikits_model(lda, spam_test_data, spam_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Same as above, except arbitrary Gaussians (i.e., each class with its own covariance matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17447916666666666"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(spam_data, np.ravel(spam_labels))\n",
    "test_scikits_model(qda, spam_test_data, spam_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Averaged Percepton w/ Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_feature_expansion(features):\n",
    "    original = features\n",
    "    squared = features ** 2\n",
    "    cartesian = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.6 Logistic Regression w/ Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "class AveragedPerceptron(object):\n",
    "\n",
    "    '''An averaged perceptron, as implemented by Matthew Honnibal.\n",
    "\n",
    "    See more implementation details here:\n",
    "        http://honnibal.wordpress.com/2013/09/11/a-good-part-of-speechpos-tagger-in-about-200-lines-of-python/\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        # Each feature gets its own weight vector, so weights is a dict-of-dicts\n",
    "        self.weights = {}\n",
    "        self.classes = set()\n",
    "        # The accumulated values, for the averaging. These will be keyed by\n",
    "        # feature/clas tuples\n",
    "        self._totals = defaultdict(int)\n",
    "        # The last time the feature was changed, for the averaging. Also\n",
    "        # keyed by feature/clas tuples\n",
    "        # (tstamps is short for timestamps)\n",
    "        self._tstamps = defaultdict(int)\n",
    "        # Number of instances seen\n",
    "        self.i = 0\n",
    "\n",
    "    def predict(self, features):\n",
    "        '''Dot-product the features and current weights and return the best label.'''\n",
    "        scores = defaultdict(float)\n",
    "        for feat, value in features.items():\n",
    "            if feat not in self.weights or value == 0:\n",
    "                continue\n",
    "            weights = self.weights[feat]\n",
    "            for label, weight in weights.items():\n",
    "                scores[label] += value * weight\n",
    "        # Do a secondary alphabetic sort, for stability\n",
    "        return max(self.classes, key=lambda label: (scores[label], label))\n",
    "\n",
    "    def update(self, truth, guess, features):\n",
    "        '''Update the feature weights.'''\n",
    "        def upd_feat(c, f, w, v):\n",
    "            param = (f, c)\n",
    "            self._totals[param] += (self.i - self._tstamps[param]) * w\n",
    "            self._tstamps[param] = self.i\n",
    "            self.weights[f][c] = w + v\n",
    "\n",
    "        self.i += 1\n",
    "        if truth == guess:\n",
    "            return None\n",
    "        for f in features:\n",
    "            weights = self.weights.setdefault(f, {})\n",
    "            upd_feat(truth, f, weights.get(truth, 0.0), 1.0)\n",
    "            upd_feat(guess, f, weights.get(guess, 0.0), -1.0)\n",
    "        return None\n",
    "\n",
    "    def average_weights(self):\n",
    "        '''Average weights from all iterations.'''\n",
    "        for feat, weights in self.weights.items():\n",
    "            new_feat_weights = {}\n",
    "            for clas, weight in weights.items():\n",
    "                param = (feat, clas)\n",
    "                total = self._totals[param]\n",
    "                total += (self.i - self._tstamps[param]) * weight\n",
    "                averaged = round(total / float(self.i), 3)\n",
    "                if averaged:\n",
    "                    new_feat_weights[clas] = averaged\n",
    "            self.weights[feat] = new_feat_weights\n",
    "        return None\n",
    "\n",
    "    def save(self, path):\n",
    "        '''Save the pickled model weights.'''\n",
    "        return pickle.dump(dict(self.weights), open(path, 'w'))\n",
    "\n",
    "    def load(self, path):\n",
    "        '''Load the pickled model weights.'''\n",
    "        self.weights = pickle.load(open(path))\n",
    "        return None\n",
    "\n",
    "\n",
    "def train(nr_iter, examples):\n",
    "    '''Return an averaged perceptron model trained on ``examples`` for\n",
    "    ``nr_iter`` iterations.\n",
    "    '''\n",
    "    model = AveragedPerceptron()\n",
    "    for i in range(nr_iter):\n",
    "        random.shuffle(examples)\n",
    "        for features, class_ in examples:\n",
    "            scores = model.predict(features)\n",
    "            guess, score = max(scores.items(), key=lambda i: i[1])\n",
    "            if guess != class_:\n",
    "                model.update(class_, guess, features)\n",
    "    model.average_weights()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
