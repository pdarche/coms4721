{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "spam = loadmat('./homework2/data/spam_fixed.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_data = spam['data']\n",
    "spam_labels = spam['labels']\n",
    "spam_test_data = spam['testdata']\n",
    "spam_test_labels = spam['testlabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_errors(predictions, labels):\n",
    "    \"\"\" Generates a list of indexes of misclassified \n",
    "    examples\n",
    "    \"\"\"\n",
    "    zipped = zip(predictions, labels)\n",
    "    errors = [ix for ix, tup in enumerate(zipped)\n",
    "              if tup[0] != tup[1]]\n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_scikits_model(clf, test_data, test_labels):\n",
    "    preds = clf.predict(test_data)\n",
    "    errors = compute_errors(preds, [t[0] for t in test_labels])\n",
    "\n",
    "    return len(errors) / test_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combinations(x):\n",
    "    combos = np.array(list(itertools.combinations(x,2)))\n",
    "    x_prime = np.array([x1 * x2.T for x1, x2 in combos])\n",
    "    \n",
    "    return x_prime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expand_features(features):\n",
    "    original = features\n",
    "    squared = features ** 2\n",
    "    combos = combinations(features)\n",
    "    return np.concatenate([original, squared, combos])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Averaged-Perceptron with 64 passes through the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(features,  weights):\n",
    "    \"\"\" \n",
    "    Predicts a label (1, -1) given a vector \n",
    "    of features and weights\n",
    "    \n",
    "    Args:\n",
    "        features:\n",
    "        weights:\n",
    "\n",
    "    Return:\n",
    "        prediction: int of -1 or 1\n",
    "    \"\"\"\n",
    "    prediction = np.dot(features, weights)\n",
    "    if prediction > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(prediction, label, features, weights):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        prediction: int of predicted label (1 or -1)\n",
    "        label: the true label of the data point (1 or -1)\n",
    "        features: numpy array of feature values\n",
    "        weights: 1d numpy array of weights for the features\n",
    "    \n",
    "    Returns:\n",
    "        weights: \n",
    "    \"\"\"\n",
    "    if prediction != label:\n",
    "        weights = weights + (label * features)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perceptron_fit(examples):\n",
    "    \"\"\" \n",
    "    Generates a vector of weights\n",
    "    \n",
    "    Args:\n",
    "        examples: vector of feature, label tuples\n",
    "    \n",
    "    Returns:\n",
    "        weights: d-dimensional vector of weights\n",
    "    \"\"\"\n",
    "    weights = np.zeros(examples[0][0].shape)\n",
    "    for features, label in examples:\n",
    "        prediction = predict(features, weights)\n",
    "        weights = update_weights(prediction, label[0], \n",
    "                                 features, weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add trained bias to signature and prediction\n",
    "def test_perceptron_model(predict, testdata, testlabels, trained_weights):\n",
    "    \"\"\" Generates predictions from a trained weight vector \"\"\"\n",
    "    preds = [predict(features, trained_weights)\n",
    "             for features in testdata]\n",
    "    errors = compute_errors(preds, [t[0] for t in testlabels])\n",
    "    \n",
    "    return len(errors) / testlabels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_perceptron_train(num_iterations, examples):\n",
    "    weights = np.zeros(examples[0][0].shape)\n",
    "    cweights = np.zeros(examples[0][0].shape)\n",
    "    bias = 0\n",
    "    cbias = 0\n",
    "    counter = 1\n",
    "    \n",
    "    for iteration in range(0, num_iterations):\n",
    "        np.random.shuffle(examples)\n",
    "        for features, label in examples:\n",
    "            if np.dot(features, weights) + bias <= 0:\n",
    "                # update the weights for this iteration\n",
    "                weights = weights + (label * features)\n",
    "                bias = bias + label\n",
    "                # update the cached weights\n",
    "                cweights = cweights + (label * counter * features)\n",
    "                cbias = bias + (label * counter)\n",
    "            counter += 1\n",
    "            \n",
    "    return (weights - ((1/counter) * cweights), bias - ((1/counter) * cbias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_perceptron_train(num_iterations, examples):\n",
    "    weights = np.zeros(examples[0][0].shape)\n",
    "    cweights = np.zeros(examples[0][0].shape)\n",
    "    bias = 0\n",
    "    counter = 1\n",
    "    \n",
    "    for iteration in range(0, num_iterations):\n",
    "        np.random.shuffle(examples)\n",
    "        for features, label in examples:\n",
    "            if np.dot(features, weights) <= 0:\n",
    "                # update the weights for this iteration\n",
    "                weights = weights + (label * features)\n",
    "                # update the cached weights\n",
    "                cweights = cweights + (label * counter * features)\n",
    "            counter += 1\n",
    "            \n",
    "    return weights - ((1/counter) * cweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_perceptron_test(features, weights, bias):\n",
    "    activation = np.dot(features, weights) + bias\n",
    "    if activation > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14583333333333334"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Averaged-Perceptron with 64 passes through the data.\n",
    "spam_examples = zip(spam_data, spam_labels)\n",
    "trained_weights = avg_perceptron_train(64, spam_examples)\n",
    "test_perceptron_model(predict, spam_test_data, spam_test_labels, trained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Logistic regression model with MLE for parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07747395833333333"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(spam_data, np.ravel(spam_labels))\n",
    "test_scikits_model(clf, spam_test_data, spam_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3  Generative model classifier where class conditional distributions are multivariate Gaussian distributions with shared covariance matrix for all classes. Use MLE for parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12239583333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(spam_data, np.ravel(spam_labels))\n",
    "test_scikits_model(lda, spam_test_data, spam_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Same as above, except arbitrary Gaussians (i.e., each class with its own covariance matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17447916666666666"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(spam_data, np.ravel(spam_labels))\n",
    "test_scikits_model(qda, spam_test_data, spam_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Averaged Percepton w/ Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_expanded = np.array([expand_features(x) for x in spam_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_test_expanded = np.array([expand_features(x) for x in spam_test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expanded_examples = zip(spam_expanded, spam_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6126302083333334"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_weights = avg_perceptron_train(64, expanded_examples)\n",
    "test_perceptron_model(predict, spam_test_expanded, spam_test_labels, trained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.6 Logistic Regression w/ Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07747395833333333"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(spam_expanded, np.ravel(spam_labels))\n",
    "test_scikits_model(clf, spam_test_expanded, spam_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
