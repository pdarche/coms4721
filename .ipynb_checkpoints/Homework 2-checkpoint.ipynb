{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "spam = loadmat('./homework2/data/spam.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_data = spam['data']\n",
    "spam_labels = spam['labels']\n",
    "spam_test_data = spam['testdata']\n",
    "spam_test_labels = spam['testlabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_tups = zip(spam_data, spam_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.06800000e+01,  -3.55120000e+02,  -6.99900000e+01,\n",
       "         3.42400000e+01,  -7.53300000e+01,   1.10500000e+01,\n",
       "         8.65700000e+01,   3.59000000e+01,   1.67000000e+01,\n",
       "        -9.03000000e+01,   1.98500000e+01,  -4.24100000e+02,\n",
       "        -4.88000000e+00,   6.10000000e-01,   2.51700000e+01,\n",
       "         1.16430000e+02,   5.09100000e+01,   1.56000000e+00,\n",
       "        -5.42140000e+02,   3.75300000e+01,   1.76900000e+01,\n",
       "         1.19400000e+02,   8.28900000e+01,   4.26400000e+01,\n",
       "        -9.76130000e+02,  -4.69150000e+02,  -6.70280000e+02,\n",
       "        -2.12610000e+02,  -2.03030000e+02,  -1.77080000e+02,\n",
       "        -1.13970000e+02,  -9.68500000e+01,  -1.77620000e+02,\n",
       "        -9.70000000e+01,  -1.85520000e+02,  -1.50830000e+02,\n",
       "        -2.26000000e+02,  -2.12100000e+01,  -1.48390000e+02,\n",
       "        -8.22000000e+01,  -1.02580000e+02,  -2.04150000e+02,\n",
       "        -8.95400000e+01,  -1.32930000e+02,  -4.40890000e+02,\n",
       "        -3.40390000e+02,  -7.60000000e+00,  -6.84500000e+01,\n",
       "        -4.19620000e+01,  -1.47149000e+02,  -3.11760000e+01,\n",
       "         1.96760000e+01,   4.62720000e+01,  -2.04000000e-01,\n",
       "        -1.05112900e+03,   1.34200000e+03,   6.96000000e+02])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(features,  weights):\n",
    "    prediction = np.dot(features, weights)\n",
    "    if prediction > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(prediction, label, features, weights):\n",
    "    if prediction != label:\n",
    "        weights = weights + (label * features)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit(examples):\n",
    "    weights = np.zeros(examples[0][0].shape)\n",
    "    for features, label in examples:\n",
    "        prediction = predict(features, weights)\n",
    "        weights = update_weights(prediction, label, \n",
    "                                 features, weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_errors(predictions, labels):\n",
    "    zipped = zip(predictions, labels)\n",
    "    errors = [ix for ix in enumerate(zipped) \n",
    "              if zipped[0] != zipped[1]]\n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(testdata, testlabels, model):\n",
    "    preds = [predict(features, model) \n",
    "             for features in testdata]\n",
    "    errors = compute_errors(preds, [t[0] for t in testlabels])\n",
    "    \n",
    "#     return len(errors) / testlabels.shape[0]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Averaged-Perceptron with 64 passes through the data.\n",
    "test_model(spam_test_data, spam_test_labels, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Logistic regression model with MLE for parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Generative model classifier where class conditional distributions are multivariate Gaussian\n",
    "# distributions with shared covariance matrix for all classes. Use MLE for parameter estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. Same as above, except arbitrary Gaussians (i.e., each class with its own covariance matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5&6. Averaged-Perceptron and logistic regression as above, with feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "class AveragedPerceptron(object):\n",
    "\n",
    "    '''An averaged perceptron, as implemented by Matthew Honnibal.\n",
    "\n",
    "    See more implementation details here:\n",
    "        http://honnibal.wordpress.com/2013/09/11/a-good-part-of-speechpos-tagger-in-about-200-lines-of-python/\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        # Each feature gets its own weight vector, so weights is a dict-of-dicts\n",
    "        self.weights = {}\n",
    "        self.classes = set()\n",
    "        # The accumulated values, for the averaging. These will be keyed by\n",
    "        # feature/clas tuples\n",
    "        self._totals = defaultdict(int)\n",
    "        # The last time the feature was changed, for the averaging. Also\n",
    "        # keyed by feature/clas tuples\n",
    "        # (tstamps is short for timestamps)\n",
    "        self._tstamps = defaultdict(int)\n",
    "        # Number of instances seen\n",
    "        self.i = 0\n",
    "\n",
    "    def predict(self, features):\n",
    "        '''Dot-product the features and current weights and return the best label.'''\n",
    "        scores = defaultdict(float)\n",
    "        for feat, value in features.items():\n",
    "            if feat not in self.weights or value == 0:\n",
    "                continue\n",
    "            weights = self.weights[feat]\n",
    "            for label, weight in weights.items():\n",
    "                scores[label] += value * weight\n",
    "        # Do a secondary alphabetic sort, for stability\n",
    "        return max(self.classes, key=lambda label: (scores[label], label))\n",
    "\n",
    "    def update(self, truth, guess, features):\n",
    "        '''Update the feature weights.'''\n",
    "        def upd_feat(c, f, w, v):\n",
    "            param = (f, c)\n",
    "            self._totals[param] += (self.i - self._tstamps[param]) * w\n",
    "            self._tstamps[param] = self.i\n",
    "            self.weights[f][c] = w + v\n",
    "\n",
    "        self.i += 1\n",
    "        if truth == guess:\n",
    "            return None\n",
    "        for f in features:\n",
    "            weights = self.weights.setdefault(f, {})\n",
    "            upd_feat(truth, f, weights.get(truth, 0.0), 1.0)\n",
    "            upd_feat(guess, f, weights.get(guess, 0.0), -1.0)\n",
    "        return None\n",
    "\n",
    "    def average_weights(self):\n",
    "        '''Average weights from all iterations.'''\n",
    "        for feat, weights in self.weights.items():\n",
    "            new_feat_weights = {}\n",
    "            for clas, weight in weights.items():\n",
    "                param = (feat, clas)\n",
    "                total = self._totals[param]\n",
    "                total += (self.i - self._tstamps[param]) * weight\n",
    "                averaged = round(total / float(self.i), 3)\n",
    "                if averaged:\n",
    "                    new_feat_weights[clas] = averaged\n",
    "            self.weights[feat] = new_feat_weights\n",
    "        return None\n",
    "\n",
    "    def save(self, path):\n",
    "        '''Save the pickled model weights.'''\n",
    "        return pickle.dump(dict(self.weights), open(path, 'w'))\n",
    "\n",
    "    def load(self, path):\n",
    "        '''Load the pickled model weights.'''\n",
    "        self.weights = pickle.load(open(path))\n",
    "        return None\n",
    "\n",
    "\n",
    "def train(nr_iter, examples):\n",
    "    '''Return an averaged perceptron model trained on ``examples`` for\n",
    "    ``nr_iter`` iterations.\n",
    "    '''\n",
    "    model = AveragedPerceptron()\n",
    "    for i in range(nr_iter):\n",
    "        random.shuffle(examples)\n",
    "        for features, class_ in examples:\n",
    "            scores = model.predict(features)\n",
    "            guess, score = max(scores.items(), key=lambda i: i[1])\n",
    "            if guess != class_:\n",
    "                model.update(class_, guess, features)\n",
    "    model.average_weights()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
